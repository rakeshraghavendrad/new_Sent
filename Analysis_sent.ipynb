{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4766bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import speech_recognition as sr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from monkeylearn import MonkeyLearn\n",
    "from moviepy.editor import ffmpeg_tools  \n",
    "import moviepy.editor as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "import sys\n",
    "import time \n",
    "import language_tool_python\n",
    "from textblob import TextBlob\n",
    "import librosa\n",
    "import requests\n",
    "import os, shutil\n",
    "import json\n",
    "#-----------------------------------------Define Path-------------------------------------------------------------------#\n",
    "path = '/home/ubuntu/new_Sent/videos/'\n",
    "path1 = \"/home/ubuntu/new_Sent/aud/\"\n",
    "get_File_names = 'https://ibridge360.com/api/UserAnswersAndScores/getFilenames'\n",
    "populate_DB = 'https://ibridge360.com/api/UserAnswersAndScores/addSentimentData'\n",
    "#---------------------------------------------------------------------------------------------------------------------#\n",
    "# Video's Downloded from S3\n",
    "url = get_File_names \n",
    "#url = 'http://dev.ibridge360.com/api/UserAnswersAndScores/addSentimentData'\n",
    "re = requests.get(url)\n",
    "#r = re.content\n",
    "js = json.loads(re.text)\n",
    "#--------------------------------------------------------------------------------------------------------------#\n",
    "ACCESS_KEY = str(input('Please enter Access Key:-     '))\n",
    "SECRET_KEY =str(input('Please enter Secret Access Key:-    '))\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,aws_secret_access_key=SECRET_KEY)\n",
    "s3 = session.resource('s3')\n",
    "your_bucket = s3.Bucket('ibridge') \n",
    "filename = []\n",
    "for s3_file in your_bucket.objects.all():\n",
    "    g = s3_file.size/1000000 \n",
    "    if(g > 3.00):\n",
    "        filename.append(s3_file.key)       \n",
    "s3 = boto3.client('s3',aws_access_key_id = ACCESS_KEY,aws_secret_access_key= SECRET_KEY)\n",
    "filename1 = []\n",
    "#---------------Fltering already analysed video--------------------------------------------------------------------------#\n",
    "print(\"The videos are being fetched, please wait\")\n",
    "\n",
    "for s2_file in filename:\n",
    "    if(s2_file.startswith(\"videos/\")):\n",
    "        if any(s2_file[7:] in s for s in js):\n",
    "            filename1.append(s2_file)\n",
    "            #print('file exist')\n",
    "        #else:\n",
    "            #filename1.append(s2_file)\n",
    "for l in range(len(filename1)):\n",
    "    path2 = \"/home/ubuntu/new_Sent/\"\n",
    "    s3.download_file('ibridge',filename1[l],path2+filename1[l])\n",
    " \n",
    "#-------------------------------DATA Analysis Part------------------------------------------------#\n",
    "\n",
    "global a    \n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".mp4\"):\n",
    "        b = os.path.getsize(path+filename)\n",
    "        b = b/1000000\n",
    "        if (b >2.00):\n",
    "            gc.collect()\n",
    "            file_name = path+filename\n",
    "            wav_file_name = path1+filename +\".wav\"\n",
    "            ffmpeg_tools.ffmpeg_extract_audio(file_name, wav_file_name)\n",
    "            du = librosa.get_duration(filename = wav_file_name)\n",
    "            if(du < 60):\n",
    "                du = du,'in Sec'\n",
    "            else:\n",
    "                du = du/60\n",
    "                du = round(du, 2)\n",
    "                du = du, 'in Min'\n",
    "             \n",
    "            r = sr.Recognizer()\n",
    "            with sr.AudioFile(wav_file_name) as source :\n",
    "                     audio = r.record(source)\n",
    "            try:\n",
    "                a = r.recognize_google(audio)\n",
    "                #print(a)\n",
    "                if (len(a) > 0):\n",
    "                    gc.collect()\n",
    "                    ml = MonkeyLearn('2d14ec2555abc7f9e2aefee982e212d9091e310a')\n",
    "                    data = [a]\n",
    "                    model_id = 'cl_pi3C7JiL'\n",
    "                    result = ml.classifiers.classify(model_id, data)\n",
    "                    t = result.body[0]\n",
    "                    classifications = t['classifications']\n",
    "                    x = pd.DataFrame(classifications)\n",
    "                    X1 = x.drop(['tag_id'], axis = 1)\n",
    "                    X2 = X1.drop(['tag_name'], axis = 1)\n",
    "                    X2.columns =[\"\"]\n",
    "                    X2 = X2.values\n",
    "                    X2 = X2.ravel()\n",
    "                    X3 = X1.drop(['confidence'], axis = 1)\n",
    "                    X3.columns =[\"\"]\n",
    "                    X3 = X3.values\n",
    "                    X3 = X3.ravel()\n",
    "                    X2 = X2 * 100\n",
    "                    list1 = [X3 , ':-' ,str(X2),'%']\n",
    "                    str1 = ''.join(map(str, list1))\n",
    "                    tl = language_tool_python.LanguageTool('en-IN')\n",
    "                    txt = a\n",
    "                    m = tl.check(txt)\n",
    "                    c = (len(m)-1)\n",
    "                    def convert(lst):\n",
    "                        return ([i for item in lst for i in item.split()])\n",
    "                    data= [a]\n",
    "                    lst =  data\n",
    "                    lst = convert(lst)\n",
    "                    mistakes = 0\n",
    "                    for x in lst:\n",
    "                        a1 = TextBlob(x)\n",
    "                        if (a1.correct() != x):\n",
    "                            mistakes = mistakes + 1\n",
    "\n",
    "                    l1 =[filename]\n",
    "                    l2 =[str1]\n",
    "                    l3 =[str(c)]\n",
    "                    l4 =[mistakes]\n",
    "                    l5 = [du]\n",
    "                    #data = pd.DataFrame(list(zip(l1, l2, l3, l4, l5)))\n",
    "                    data = pd.DataFrame(list(zip(l1,l2, l3, l4, l5)))\n",
    "                    data.columns =['Filename','Sentiment Analysis','Total Grammatical Errors','Total Spelling Errors','Total duration']\n",
    "                    data.to_csv(\"Analysis_AWS_data.csv\",mode='a')\n",
    "                    print(\"Data transcribed Successful\")\n",
    "                    del a\n",
    "                   \n",
    "            except:\n",
    "                print(\"Sorry, I did not get that\") \n",
    "                error = \"Issues while recording/microphone muted/disturbed environment\"\n",
    "                l1 =[filename]\n",
    "                l4 =[error]\n",
    "                data_e = pd.DataFrame(list(zip(l1, l4)))\n",
    "                data_e.columns =['Filename', 'ERROR MESSAGE']\n",
    "                data_e.to_csv(\"Error_Analysis.csv\",mode='a')\n",
    "                print(\"Data transcribed to error\")\n",
    "\n",
    "if (os.path.isfile('Error_Analysis.csv') and os.path.isfile('Analysis_AWS_data.csv')):\n",
    "#try:\n",
    "    df = pd.read_csv('Analysis_AWS_data.csv')\n",
    "    du1=df.drop_duplicates()\n",
    "    df1 = du1.loc[:, ~du1.columns.str.contains('^Unnamed')]\n",
    "    df1.index.name = 'Index'\n",
    "    #df1 =df1.drop(df1.index[1])\n",
    "    #blankIndex=[''] * len(df1)\n",
    "    #df1.index=blankIndex\n",
    "    #df1.to_csv(\"Final_Analysis.csv\",mode='a')\n",
    "    print('Analysis Done')\n",
    "#--------------------------------------------------ANALYSIS FROM AWS---------------------------------------------------#\n",
    "    ds = pd.read_csv(\"Error_Analysis.csv\")\n",
    "    ds1=ds.drop_duplicates()\n",
    "    ds1 = ds1.loc[:, ~ds1.columns.str.contains('^Unnamed')]\n",
    "    ds1.index.name = 'Index'\n",
    "\n",
    "    #blankIndex=[''] * len(ds1)\n",
    "    #ds1.index=blankIndex\n",
    "\n",
    "#------------------------------------------------------------ANALYSIS ERROR DATA----------------------------------------#\n",
    "    fl = pd.concat([df1,ds1])\n",
    "    fl.to_csv(\"fnl_n.csv\")\n",
    "#n_df = pd.read_csv(\"fnl.csv\")\n",
    "#co = pd.concat([n_df,f1])\n",
    "#co.to_csv(\"fnl.csv\")\n",
    "    print('final .csv is printed go check it out from try block')\n",
    "#----------------------------------Populating to mongo DB ----------------------------------------------------#\n",
    "    url1 = populate_DB\n",
    "    s = pd.read_csv('fnl_n.csv')\n",
    "    s.fillna('N/A', inplace = True)\n",
    "    for index, row in s.iterrows():\n",
    "         myobj = {\n",
    "            \"communicationVideoName\":str(row['Filename']),\n",
    "            \"finalAssessment\":str(row['Sentiment Analysis']),\n",
    "            \"totalDuration\":str(row['Total duration']),\n",
    "            \"spellingErrors\":str(row['Total Spelling Errors']),\n",
    "            \"grammaticalErrors\":str(row['Total Grammatical Errors']),\n",
    "            \"errorMessage\":str(row['ERROR MESSAGE'])\n",
    "            }\n",
    "\n",
    "         x = requests.post(url1, data = myobj)\n",
    "\n",
    "         print(x.text)\n",
    "         #print(\"I am From try block\")\n",
    "#----------------------------DELETING ALL VIDEO AND AUDIO FROM LOCAL DIR-------------------------------------------#\n",
    "    folder = path\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    import os, shutil\n",
    "    folder1 = path1\n",
    "    for filename in os.listdir(folder1):\n",
    "        file_path = os.path.join(folder1, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "#--------------------------------------------------Deleting file after combining ----------------------------------------#\n",
    "    file = 'Analysis_AWS_data.csv'\n",
    "    file1 = 'Error_Analysis.csv'\n",
    "    if(os.path.exists(file1) and os.path.isfile(file1)):\n",
    "            os.remove(file1)\n",
    "            print(\"file deleted\",file1)\n",
    "    if(os.path.exists(file) and os.path.isfile(file)):\n",
    "            os.remove(file)\n",
    "            print(\"file deleted\",file)\n",
    "#---------------------------------------------DELETING FNL_N FILE FROM LOCAL DIR-------------------------------------------#\n",
    "    file2 = 'fnl_n.csv'\n",
    "    if(os.path.exists(file2) and os.path.isfile(file2)):\n",
    "              os.remove(file2)\n",
    "              print(\"file deleted\",file2)\n",
    "              print(\"program completed successfully and Populated values in databases\")\n",
    "#-----------------------------------------------------------END of if block-------------------------------------------------------------#\n",
    "elif(os.path.isfile('Error_Analysis.csv')):\n",
    "    ds = pd.read_csv(\"Error_Analysis.csv\")\n",
    "    ds1 = ds.drop_duplicates()\n",
    "    ds1 = ds1.loc[:, ~ds1.columns.str.contains('^Unnamed')]\n",
    "    ds1.index.name = 'Index'\n",
    "    print('Analysis Done')\n",
    "#------------------------------------checking for Error_analysis.csv-----------------------------------------------------------------------------#\n",
    "    folder = path\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    import os, shutil\n",
    "\n",
    "    folder1 = path1\n",
    "    for filename in os.listdir(folder1):\n",
    "        file_path = os.path.join(folder1, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    # --------------------deleting all the videos and audios --------------------------------------------------------------------#\n",
    "    url = populate_DB\n",
    "    s = pd.read_csv('Error_Analysis.csv')\n",
    "    s.fillna('N/A', inplace=True)\n",
    "    for index, row in s.iterrows():\n",
    "        myobj = {\n",
    "            \"communicationVideoName\": str('N/A'),\n",
    "            \"finalAssessment\": str('N/A'),\n",
    "            \"totalDuration\": str('N/A'),\n",
    "            \"spellingErrors\": str('N/A'),\n",
    "            \"grammaticalErrors\": str('N/A'),\n",
    "            \"errorMessage\": str(row['ERROR MESSAGE'])\n",
    "        }\n",
    "\n",
    "        x = requests.post(url, data=myobj)\n",
    "\n",
    "        print(x.text)\n",
    "        # print(\"I am From Except block\")\n",
    "    # --------------------populating MondoDB-------------------------------------------------------------------------------------#\n",
    "    file2 = 'Error_Analysis.csv'\n",
    "    if (os.path.exists(file2) and os.path.isfile(file2)):\n",
    "        os.remove(file2)\n",
    "        print(\"file deleted\", file2)\n",
    "        print(\"program completed successfully and Populated values in databases\")\n",
    "#--------------------------------Deleting ERROR_ANALYSIS.csvfile(end of elif block)-------------------------------------------------------------#\n",
    "elif(os.path.isfile('Analysis_AWS_data.csv')):\n",
    "    df = pd.read_csv('Analysis_AWS_data.csv')\n",
    "    du1=df.drop_duplicates()\n",
    "    df1 = du1.loc[:, ~du1.columns.str.contains('^Unnamed')]\n",
    "    df1.index.name = 'Index'\n",
    "    #df1 =df1.drop(df1.index[1])\n",
    "    #blankIndex=[''] * len(df1)\n",
    "    #df1.index=blankIndex\n",
    "    #df1.to_csv(\"Final_Analysis.csv\",mode='a')\n",
    "    print('Analysis Done')\n",
    "#-#----------------------------DELETING ALL VIDEO AND AUDIO FROM LOCAL DIR----------------------------------------------------#\n",
    "    folder = path\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    import os, shutil\n",
    "    folder1 = path1\n",
    "    for filename in os.listdir(folder1):\n",
    "        file_path = os.path.join(folder1, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "#-----#----------------------------------Populating to mongo DB ----------------------------------------------------#\n",
    "    url = populate_DB\n",
    "    s = pd.read_csv('Analysis_AWS_data.csv')\n",
    "    s.fillna('N/A', inplace = True)\n",
    "    for index, row in s.iterrows():\n",
    "         myobj = {\n",
    "            \"communicationVideoName\":str(row['Filename']),\n",
    "            \"finalAssessment\":str(row['Sentiment Analysis']),\n",
    "            \"totalDuration\":str(row['Total duration']),\n",
    "            \"spellingErrors\":str(row['Total Spelling Errors']),\n",
    "            \"grammaticalErrors\":str(row['Total Grammatical Errors']),\n",
    "            \"errorMessage\":str('N/A')\n",
    "            }\n",
    "\n",
    "         x = requests.post(url, data = myobj)\n",
    "\n",
    "         print(x.text)\n",
    "         #print(\"I am From Except block\")\n",
    "#---------------------------------------------DELETING Analysis_AWS_data FILE FROM LOCAL DIR-------------------------------------------\n",
    "    file2 = 'Analysis_AWS_data.csv'\n",
    "    if(os.path.exists(file2) and os.path.isfile(file2)):\n",
    "            os.remove(file2)\n",
    "            print(\"file deleted\",file2)\n",
    "            print(\"program completed successfully and Populated values in databases\")\n",
    "else:\n",
    "    print(\"None of the video met the criteria\")\n",
    "#--------------------------------END OF PRGM-----------------------------------------------------------------------------#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0bda56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
